{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Reduce decimal points to 2\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# initialise progress_apply\n",
    "tqdm.pandas(desc=\"my bar!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import date and drop useless column\n",
    "path = os.getcwd()\n",
    "\n",
    "data = pd.read_csv('{}/data_assignment_1.csv'.format(path))\n",
    "\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "year            0\n",
      "yearest     67916\n",
      "industry    79437\n",
      "pertot      79437\n",
      "enggrad     73439\n",
      "sales       79541\n",
      "va          79835\n",
      "gom         79843\n",
      "rdint       79720\n",
      "reext       79544\n",
      "ipnc        81662\n",
      "ipnf        81665\n",
      "ipnm        81660\n",
      "ipr         79454\n",
      "patent      79504\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# take a first look at the number of NAs\n",
    "print(data.isna().sum())\n",
    "initial_length = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si on supprimait directement tous les NAs, il nous resterait 30742 lignes \n",
      "\n",
      "Attention, le dataframe ressemblerait à un gruyère (plusieurs années disparaîtraient pour chaque entreprise)\n"
     ]
    }
   ],
   "source": [
    "print('Si on supprimait directement tous les NAs, il nous resterait', len(data.dropna()), 'lignes', '\\n')\n",
    "print('Attention, le dataframe ressemblerait à un gruyère (plusieurs années disparaîtraient pour chaque entreprise)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting companies with more than 11 NAs in a column \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5304/5304 [01:13<00:00, 72.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling NAs in the columns of the remaining companies \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1216/1216 [00:17<00:00, 68.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# loop to delete companies with more than 11 NAs in a column\n",
    "print('deleting companies with more than 11 NAs in a column', '\\n')\n",
    "for i in tqdm(data['id'].unique()):\n",
    "\n",
    "    for column in data.columns:\n",
    "        # print(data.loc[data['id'] == i, [column]].isna().sum().iloc[0])\n",
    "        if data.loc[data['id'] == i, [column]].isna().sum().iloc[0] > 11:\n",
    "            data.drop(data[data['id'] == i].index, inplace=True)\n",
    "            # print('deleting company', i)\n",
    "            break\n",
    "\n",
    "\n",
    "# loop to fill the NAs for each company\n",
    "print('filling NAs in the columns of the remaining companies', '\\n')\n",
    "for i in tqdm(data['id'].unique()):\n",
    "        \n",
    "    try: \n",
    "        # fill NAs with the variable mode for industry and yearest (makes more sense to our minds)\n",
    "        data.loc[data['id'] == i, ['industry']] = data.loc[data['id'] == i, ['industry']].mode(axis=0, dropna=True).iloc[0, 0]\n",
    "        data.loc[data['id'] == i, ['yearest']] = data.loc[data['id'] == i, ['yearest']].mode(axis=0, dropna=True).iloc[0, 0]\n",
    "\n",
    "        # interpolate the columns where variables are continuous\n",
    "        continuous_variables = ['enggrad', 'sales', 'va', 'gom','rdint', 'reext']\n",
    "        data.loc[data['id'] == i, continuous_variables] = data.loc[data['id'] == i, continuous_variables].interpolate(method='linear', axis=0, limit_direction='both')\n",
    "\n",
    "        # interpolate the columns where variables are discrete\n",
    "        discrete_variables = ['pertot', 'patent']\n",
    "        data.loc[data['id'] == i, discrete_variables] = data.loc[data['id'] == i, discrete_variables].interpolate(method='linear', axis=0, limit_direction='both').round(0)\n",
    "\n",
    "        # fill NAs in binary variables\n",
    "        binary_variables = ['ipnc', 'ipnf', 'ipnm', 'ipr']\n",
    "        data.loc[data['id'] == i, binary_variables] = data.loc[data['id'] == i, binary_variables].interpolate(method='linear', axis=0, limit_direction='both')\n",
    "\n",
    "    except IndexError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations: 27968 \n",
      "\n",
      "94024 rows have been deleted during the process \n",
      "\n",
      "number of NAs for each column: \n",
      " id          0\n",
      "year        0\n",
      "yearest     0\n",
      "industry    0\n",
      "pertot      0\n",
      "enggrad     0\n",
      "sales       0\n",
      "va          0\n",
      "gom         0\n",
      "rdint       0\n",
      "reext       0\n",
      "ipnc        0\n",
      "ipnf        0\n",
      "ipnm        0\n",
      "ipr         0\n",
      "patent      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "len_after_cleaning = len(data)\n",
    "print('number of observations:', len_after_cleaning, '\\n')\n",
    "print(initial_length - len_after_cleaning, 'rows have been deleted during the process', '\\n')\n",
    "print('number of NAs for each column:', '\\n', data.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, il reste moins de lignes en faisant ce savage cleaning que lorsque l'on supprime tous les NAs \"sans réfléchir\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create age variable\n",
    "data.insert(loc=3, column='age', value=data.apply(lambda row: row['year'] - row['yearest'], axis=1), allow_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EMCCd\\AppData\\Local\\Temp\\ipykernel_27432\\3459315293.py:2: FutureWarning: The 'fill_method' and 'limit' keywords in SeriesGroupBy.pct_change are deprecated and will be removed in a future version. Call ffill before calling pct_change instead.\n",
      "  data['sales_growth_rate'] = data.sort_values('year').groupby('id')['sales'].pct_change(fill_method=None)\n",
      "my bar!:   0%|          | 0/27968 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "my bar!: 100%|██████████| 27968/27968 [00:00<00:00, 73143.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute the sales growth rate\n",
    "data['sales_growth_rate'] = data.sort_values('year').groupby('id')['sales'].pct_change(fill_method=None)\n",
    "\n",
    "# Compute the 90th percentile of the sales growth rate for each year\n",
    "percentile_90_thresholds = data.groupby('year')['sales_growth_rate'].quantile(0.9)\n",
    "\n",
    "# Create a binary target variable based on the 90th percentile\n",
    "data['is_hgf'] = data.progress_apply(lambda row: 1 if row['sales_growth_rate'] >= percentile_90_thresholds[row['year']] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1216 more rows have been deleted\n"
     ]
    }
   ],
   "source": [
    "# drop the remaining NAs (in the sales_growth_rate and is_hgf variables) to perform model training and predictions\n",
    "data = data.dropna()\n",
    "print(len_after_cleaning - len(data), 'more rows have been deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data types\n",
    "\n",
    "data_types_dict = {'id': int,\n",
    "                   'year': int,\n",
    "                   'yearest': int,\n",
    "                   'age': int,\n",
    "                   'industry': int,\n",
    "                   'pertot': int,\n",
    "                   'enggrad': float,\n",
    "                   'sales': float,\n",
    "                   'va': float,\n",
    "                   'gom': float,\n",
    "                   'rdint': float,\n",
    "                   'reext': float,\n",
    "                   'ipnc': bool,\n",
    "                   'ipnf': bool,\n",
    "                   'ipnm': bool,\n",
    "                   'ipr': bool,\n",
    "                   'patent': int,\n",
    "                   'sales_growth_rate': float,\n",
    "                   'is_hgf': bool}\n",
    "\n",
    "data = data.astype(data_types_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "year                 0\n",
       "yearest              0\n",
       "age                  0\n",
       "industry             0\n",
       "pertot               0\n",
       "enggrad              0\n",
       "sales                0\n",
       "va                   0\n",
       "gom                  0\n",
       "rdint                0\n",
       "reext                0\n",
       "ipnc                 0\n",
       "ipnf                 0\n",
       "ipnm                 0\n",
       "ipr                  0\n",
       "patent               0\n",
       "sales_growth_rate    0\n",
       "is_hgf               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the True_False values of the is_hgf column to 1 and 0\n",
    "data['is_hgf'] = data['is_hgf'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_hgf\n",
       "0    23610\n",
       "1     3142\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of Target Varibale\n",
    "data['is_hgf'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>yearest</th>\n",
       "      <th>age</th>\n",
       "      <th>industry</th>\n",
       "      <th>pertot</th>\n",
       "      <th>enggrad</th>\n",
       "      <th>sales</th>\n",
       "      <th>va</th>\n",
       "      <th>gom</th>\n",
       "      <th>rdint</th>\n",
       "      <th>reext</th>\n",
       "      <th>ipnc</th>\n",
       "      <th>ipnf</th>\n",
       "      <th>ipnm</th>\n",
       "      <th>ipr</th>\n",
       "      <th>patent</th>\n",
       "      <th>sales_growth_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_hgf</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,523.42</td>\n",
       "      <td>2,001.35</td>\n",
       "      <td>1,972.95</td>\n",
       "      <td>28.41</td>\n",
       "      <td>10.19</td>\n",
       "      <td>273.56</td>\n",
       "      <td>4.75</td>\n",
       "      <td>68,136,701.74</td>\n",
       "      <td>26,815,388.45</td>\n",
       "      <td>7.18</td>\n",
       "      <td>502,902.83</td>\n",
       "      <td>391,148.23</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,534.76</td>\n",
       "      <td>2,002.59</td>\n",
       "      <td>1,974.81</td>\n",
       "      <td>27.78</td>\n",
       "      <td>10.92</td>\n",
       "      <td>256.56</td>\n",
       "      <td>5.34</td>\n",
       "      <td>71,969,726.84</td>\n",
       "      <td>40,097,080.69</td>\n",
       "      <td>9.26</td>\n",
       "      <td>610,071.89</td>\n",
       "      <td>453,694.89</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id     year  yearest   age  industry  pertot  enggrad  \\\n",
       "is_hgf                                                               \n",
       "0      1,523.42 2,001.35 1,972.95 28.41     10.19  273.56     4.75   \n",
       "1      1,534.76 2,002.59 1,974.81 27.78     10.92  256.56     5.34   \n",
       "\n",
       "               sales            va  gom      rdint      reext  ipnc  ipnf  \\\n",
       "is_hgf                                                                      \n",
       "0      68,136,701.74 26,815,388.45 7.18 502,902.83 391,148.23  0.13  0.12   \n",
       "1      71,969,726.84 40,097,080.69 9.26 610,071.89 453,694.89  0.13  0.12   \n",
       "\n",
       "        ipnm  ipr  patent  sales_growth_rate  \n",
       "is_hgf                                        \n",
       "0       0.13 0.33    0.36              -0.00  \n",
       "1       0.12 0.35    0.35               1.64  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mean of the Target variable for each columns  \n",
    "data.groupby('is_hgf').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the in-put and out-put variables\n",
    "X = data.drop(columns='is_hgf', axis=1)\n",
    "Y = data['is_hgf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test data \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26752, 18) (20064, 18) (6688, 18)\n"
     ]
    }
   ],
   "source": [
    "# Print\n",
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training \n",
    "#Logistic Regression \n",
    "model = LogisticRegression()\n",
    "\n",
    "# training the Logistic Regression model using Training data\n",
    "model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation :\n",
    "# accuracy on training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train, X_train_prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data =  0.883622408293461\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on training data = ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(Y_test, X_test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data =  0.8793361244019139\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test data = ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy C=0.001 (test): 0.879\n",
      "Accuracy C=50 (test): 0.879\n"
     ]
    }
   ],
   "source": [
    "# We can change the value of C and play with the flexibility of the model\n",
    "logreg001 = LogisticRegression(max_iter=5000, C=0.001).fit(X_train, Y_train)\n",
    "logreg50 = LogisticRegression(max_iter=5000, C=50).fit(X_train, Y_train)\n",
    "\n",
    "print(\"Accuracy C=0.001 (test): {:.3f}\".format(logreg001.score(X_test, Y_test)))\n",
    "print(\"Accuracy C=50 (test): {:.3f}\".format(logreg50.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['sales_growth_rate'], axis = 1)\n",
    "y = data['sales_growth_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "ridge = Ridge(normalize = True)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ridge = ridge.fit(X_train, y_train)\n",
    "\n",
    "# Visualize coefficients\n",
    "print(pd.Series(ridge.coef_, index = X.columns))\n",
    "\n",
    "# Check the performance of the model\n",
    "print('MSE (training): %.2f' % mean_squared_error(y_train, ridge.predict(X_train)),\n",
    "      'MSE (test): %.2f' % mean_squared_error(y_test, ridge.predict(X_test)), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set manually some values for alpha\n",
    "alphas = 10**np.linspace(5,-2,100)*0.5\n",
    "alphas\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    ridge = Ridge(alpha=a, fit_intercept=False)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs.append(ridge.coef_)\n",
    "\n",
    "#Plot ridge coefficients as a function of the regularization\n",
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('coefficient')\n",
    "plt.title('Ridge coefficients profile')\n",
    "plt.axis('tight')\n",
    "plt.show()\n",
    "\n",
    "# We use cross-validation to choose the tuning parameter\n",
    "ridgecv = RidgeCV(alphas = alphas, cv = 10, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "ridgecv.alpha_\n",
    "\n",
    "\n",
    "print('MSE (training): %.2f' % mean_squared_error(y_train, ridgecv.predict(X_train)),\n",
    "      'MSE (test): %.2f' % mean_squared_error(y_test, ridgecv.predict(X_test)), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lassocv.fit(X_train, y_train)\n",
    "lassocv.alpha_\n",
    "\n",
    "# How many coeffiecient are set to zero?\n",
    "print('Number of features used:', np.sum(lassocv.coef_ != 0))\n",
    "\n",
    "print('MSE (training): %.2f' % mean_squared_error(y_train, lassocv.predict(X_train)),\n",
    "      'MSE (test): %.2f' % mean_squared_error(y_test, lassocv.predict(X_test)), sep='\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
